# hash tree
https://en.wikipedia.org/wiki/Merkle_tree
http://blog.csdn.net/yang_yulei/article/details/46337405

## 引

在一些数据结构（线性表、树等）中，数据在结构中的相对位置是随机的。因此在结构中查找数据时需要进行和一系列关键字的比较。这一类的查找方法建立在“比较”的基础上。查找的效率依赖于查找过程中所进行的比较次数。

之前我们介绍的各种基于比较的树查找算法，这些查找算法的效率都将随着数据记录数的增长而下降。仅仅是有的比较慢（时间复杂度为O(n)），有的比较快（时间复杂度是O(logn)）而已。这些查找算法的平均查找长度是在一种比较理想的情况下获得的。在实际应用当中，对数据结构中数据的频繁增加和删除将不断地改变着数据的结构。这些操作将可能导致某些数据结构退化为链表结构，那么其性能必然将下降。为了避免出现这种情况而采取的调整措施，又不可避免的增加了程序的复杂程度以及操作的额外时间。


## 哈希表 

理想的情况是希望不经过任何比较，一次存取便能得到所查的记录，那就必须在数据的**存储位置和它的关键字之间建立一个确定的对应关系**f，使每个关键字和一个唯一的存储位置相对应。因而在查找时，只要根据这个对应关系f找到给定值K的像f(K)。由此，不需要进行比较便可直接取得所查记录。在此，我们称这个对应关系为哈希（Hash）函数，按这个思想建立的表为哈希表。

在哈希表中**对于不同的关键字可能得到同一哈希地址**，这种现象称做**冲突**。在一般情况下，冲突只能尽可能地减少，而不能完全避免。因为哈希函数是从关键字集合到地址集合的映像。通常关键字的集合比较大，它的元素包括所有可能的关键字，而地址集合的元素仅为哈希表中的地址值。在一般情况下，哈希函数是一个压缩映像函数，这就不可避免的要产生冲突。

**哈希树(HashTree)**算法就是要提供一种在理论上和实际应用中均能**有效地处理冲突**的方法。一般的哈希(Hash)算法都是O(1)的，而且基本是以空间换时间。这很容易导致对存储空间无限制的需求。哈希树(HashTree)算法在实际操作中使用了一些技巧使得对空间的需求控制在一定范围内。即空间需求仅和所需要存储的对象个数有关，不会无限制地“膨胀”下去。 

## 哈希树的理论基础

【质数分辨定理】
简单地说就是：n个不同的质数可以“分辨”的连续整数的个数和他们的乘积相等。“分辨”就是指这些连续的整数不可能有完全相同的余数序列。
（这个定理的证明详见：http://wenku.baidu.com/view/16b2c7abd1f34693daef3e58.html）

任取n个互不相同的质数，$P_1,P_2,...,P_n$($n\in N$),定义：
$$M=\prod_{i=1}^{n} P_i =P_1*P_2*...*P_n $$
对于$m\le k_1 < k_2 \le m+M \quad (m,M,k_1,k_2\in N)$，对于任意$i\in [1,n]$,$(k_1\mod P_i)=(K_2\mod P_i)$不可能总成立。即两个不同的数相距小于M，这两个数mod P~i~的模数至少有一个不同。

例如：
从2起的连续质数，连续10个质数就可以分辨大约M(10) =`2*3*5*7*11*13*17*19*23*29`= 6464693230 个数，已经超过计算机中常用整数（32bit）的表达范围。连续100个质数就可以分辨大约M = 4.711930 乘以10的219次方。
而按照目前的CPU水平，100次取余的整数除法操作几乎不算什么难事。在实际应用中，整体的操作速度往往取决于节点将关键字装载内存的次数和时间。一般来说，装载的时间是由关键字的大小和硬件来决定的；在相同类型关键字和相同硬件条件下，实际的整体操作时间就主要取决于装载的次数。他们之间是一个成正比的关系。 

